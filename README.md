List of projects in this portfolio

1.	Titanic Project (DSC 530)

Using a dataset with information about the passengers of the Titanic disaster, I did an analysis to determine what the primary factors for surviving the sinking were. I did an initial EDA to get an idea of what the data holds and what needs to be cleaned up and prepared for the analysis. I then used the chi-square test to see which variables had a strong association with survival, and did both a multi-nominal logistic regression as well as a linear regression to predict the most important factors for survival.

2.	Crime Rates (DSC 540)

In this project, I took three individual datasets, and added them as tables to a mySQL database. I used the mysql_connector package to enable Python in my Jupyter Notebook to access my locally hosted mySQL database server. Using several custom helper functions, I loaded the three datasets into the database. After I decided on which visualizations I want to make, and which data I would need for them. I used SQL queries to collect the data from one or more tables into Python dataframes, and then visualized them using matplotlib.

3.	Analyzing Customer Churn in the Telecommunication Industry (DSC 630)

Based on a Kaggle dataset about customer churn in the telecommunication industry, my team and I attempted to determine how telco companies can reduce customer churn. To do so, we first did an EDA to see what data was in the dataset and how it needed to be cleaned and prepared for the next steps in the analysis. After the cleaning, we did some feature engineering by creating dummy columns, as well as reformatting yes/no columns to binaries. We used logistic regression model and random forest regressor to determine feature importance, and based on that recommend what the telcos should concentrate on to reduce customer churn.

4.	Selecting Startup Inventory for a New Chain of Beer Stores (DSC 680)

This project about a fictitious new chain of beer stores, that needed a good startup inventory. My goal was to predict which beers the store should stock in order to have the best chance of success (i.e. good sales). I used a Kaggle dataset containing data about beer reviews. It contained information about the types of beers and the features/properties of the individual beers. I did an EDA to determine what information can be gleaned from the dataset, and what cleaning and preparation would need to be done. Once the dataset was cleaned and ready for further analysis, I used a random forest regressor to determine feature importance, then calculated the most popular beer types and beers within the types, and finally produced a list of 30 styles of beers with 20 beers in each for the stores to use.


5.	DSC 680 ongoing project
6.	DSC 680 ongoing project
